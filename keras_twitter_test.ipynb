{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gabriel\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optree->keras) (4.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gabriel\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gabriel\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "# %pip install tensorflow-rocm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------------\n",
      "absl-py                      2.1.0\n",
      "annotated-types              0.6.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "beautifulsoup4               4.12.3\n",
      "blis                         0.7.11\n",
      "catalogue                    2.0.10\n",
      "certifi                      2023.11.17\n",
      "charset-normalizer           3.3.2\n",
      "click                        8.1.7\n",
      "cloudpathlib                 0.16.0\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "confection                   0.1.4\n",
      "contourpy                    1.2.1\n",
      "cycler                       0.12.1\n",
      "cymem                        2.0.8\n",
      "debugpy                      1.8.1\n",
      "decorator                    5.1.1\n",
      "dill                         0.3.7\n",
      "en-core-web-sm               3.7.1\n",
      "exceptiongroup               1.2.0\n",
      "executing                    2.0.1\n",
      "filelock                     3.12.4\n",
      "flatbuffers                  24.3.25\n",
      "fonttools                    4.51.0\n",
      "fsspec                       2023.9.2\n",
      "gast                         0.5.4\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.64.1\n",
      "h5py                         3.11.0\n",
      "html5lib                     1.1\n",
      "idna                         3.6\n",
      "ipykernel                    6.29.4\n",
      "ipython                      8.23.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.2\n",
      "joblib                       1.4.2\n",
      "jupyter_client               8.6.1\n",
      "jupyter_core                 5.7.2\n",
      "keras                        3.3.3\n",
      "kiwisolver                   1.4.5\n",
      "langcodes                    3.3.0\n",
      "libclang                     18.1.1\n",
      "lxml                         5.1.0\n",
      "Markdown                     3.6\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.8.4\n",
      "matplotlib-inline            0.1.6\n",
      "mdurl                        0.1.2\n",
      "mechanize                    0.4.9\n",
      "ml-dtypes                    0.3.2\n",
      "mpmath                       1.3.0\n",
      "murmurhash                   1.0.10\n",
      "namex                        0.0.8\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.1\n",
      "nltk                         3.8.1\n",
      "numpy                        1.26.4\n",
      "opt-einsum                   3.3.0\n",
      "optree                       0.11.0\n",
      "packaging                    24.0\n",
      "pandas                       2.2.2\n",
      "parso                        0.8.4\n",
      "pillow                       10.3.0\n",
      "pip                          24.0\n",
      "platformdirs                 4.2.0\n",
      "preshed                      3.0.9\n",
      "prompt-toolkit               3.0.43\n",
      "protobuf                     4.25.3\n",
      "psutil                       5.9.8\n",
      "pure-eval                    0.2.2\n",
      "py4j                         0.10.9.7\n",
      "pydantic                     2.6.4\n",
      "pydantic_core                2.16.3\n",
      "Pygments                     2.17.2\n",
      "pyparsing                    3.1.2\n",
      "pyspark                      3.5.0\n",
      "python-dateutil              2.8.2\n",
      "pytz                         2024.1\n",
      "pywin32                      306\n",
      "pyzmq                        25.1.2\n",
      "regex                        2024.4.28\n",
      "requests                     2.31.0\n",
      "rich                         13.7.1\n",
      "scikit-learn                 1.4.2\n",
      "scipy                        1.13.0\n",
      "seaborn                      0.13.2\n",
      "setuptools                   63.2.0\n",
      "six                          1.16.0\n",
      "smart-open                   6.4.0\n",
      "soupsieve                    2.5\n",
      "spacy                        3.7.4\n",
      "spacy-legacy                 3.0.12\n",
      "spacy-loggers                1.0.5\n",
      "srsly                        2.4.8\n",
      "stack-data                   0.6.3\n",
      "sympy                        1.12\n",
      "tensorboard                  2.16.2\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.16.1\n",
      "tensorflow-intel             2.16.1\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.4.0\n",
      "thinc                        8.2.3\n",
      "threadpoolctl                3.5.0\n",
      "torch                        2.0.0\n",
      "torch-directml               0.2.0.dev230426\n",
      "torchvision                  0.15.1\n",
      "tornado                      6.4\n",
      "tqdm                         4.66.2\n",
      "traitlets                    5.14.2\n",
      "typer                        0.9.4\n",
      "typing_extensions            4.8.0\n",
      "tzdata                       2024.1\n",
      "urllib3                      2.1.0\n",
      "wasabi                       1.1.2\n",
      "wcwidth                      0.2.13\n",
      "weasel                       0.3.4\n",
      "webencodings                 0.5.1\n",
      "Werkzeug                     3.0.3\n",
      "wheel                        0.41.2\n",
      "wrapt                        1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read headline_data\n",
    "# headline_data = pd.read_csv('analyst_ratings_processed.csv' , quotechar='\"', quoting=2, delimiter=\",\")\n",
    "\n",
    "# # subset A stock for development-stage\n",
    "# headline_data = headline_data[headline_data[\"stock\"]==\"A\"]\n",
    "\n",
    "# # Cut only date from datetime value\n",
    "# headline_data[\"date\"] = headline_data[\"date\"].apply(lambda x: x.split(\" \")[0])\n",
    "\n",
    "# # Read Stock Data (only A for development-stage)\n",
    "# raw_stock_data = pd.read_csv('A.csv')\n",
    "\n",
    "# # Preprocessing\n",
    "# raw_stock_data = raw_stock_data.rename(columns={'Date': 'date'})\n",
    "\n",
    "# # Calculate difference as boolean and numeric\n",
    "# raw_stock_data[\"diff_num\"] = raw_stock_data[\"Open\"] - raw_stock_data[\"Close\"]\n",
    "# raw_stock_data[\"diff_bool\"] = raw_stock_data[\"diff_num\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# # Add label A for joining\n",
    "# raw_stock_data[\"label\"] = \"A\"\n",
    "\n",
    "# # Make a small DF and join with headline data\n",
    "# stock_data = raw_stock_data[[\"date\",\"label\", \"diff_num\",\"diff_bool\"]]\n",
    "# #print(stock_data[stock_data[\"diff_bool\"]==1])\n",
    "# merged_df = pd.merge(headline_data, stock_data, on='date', how='inner')\n",
    "\n",
    "# # Drop unneccesary columns\n",
    "# #merged_df = merged_df.drop(merged_df.columns[0], axis=1)\n",
    "# # merged_df = merged_df.drop(columns=[\"label_x\",\"label_y\"])\n",
    "# merged_df.head()\n",
    "\n",
    "# #merged_df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df[(merged_df[\"diff_num\"]<0.01) & (merged_df[\"diff_num\"]>-0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "\n",
    "# if os.path.exists(\"big_merged_dataset.csv\"):\n",
    "#     # Read the CSV file\n",
    "#     merged_df = pd.read_csv(\"big_merged_dataset.csv\")\n",
    "#     headline_data = pd.read_csv('analyst_ratings_processed.csv' , quotechar='\"', quoting=2, delimiter=\",\")\n",
    "#     print(\"CSV file exists. DataFrame loaded successfully.\")\n",
    "# else:\n",
    "#     print(\"CSV file does not exist. Processing starts, this takes approximately 3 minutes\")\n",
    "\n",
    "#     headline_data = pd.read_csv('analyst_ratings_processed.csv' , quotechar='\"', quoting=2, delimiter=\",\")\n",
    "\n",
    "\n",
    "\n",
    "#     # Function to check if the value is a string\n",
    "#     def is_string(value):\n",
    "#         return isinstance(value, str)\n",
    "\n",
    "#     # Filter the DataFrame to keep only rows where the 'date' column is a string\n",
    "#     headline_data = headline_data[headline_data['date'].apply(is_string)]\n",
    "#     print(len(headline_data))\n",
    "\n",
    "\n",
    "\n",
    "#     headline_data[\"date\"] = headline_data[\"date\"].apply(lambda x: x.split(\" \")[0])\n",
    "#     print(\"Date processing done.\")\n",
    "\n",
    "\n",
    "\n",
    "#     # iterable list\n",
    "#     rows = list(headline_data.iterrows())\n",
    "#     print(\"Iterable list transformation done.\")\n",
    "\n",
    "#     merged_df = pd.DataFrame(columns=[\"title\",\"diff_bool\",\"stock\"])\n",
    "#     ticker = \"\"  # save the current stock ticker\n",
    "#     start_block_idx = 0     # save the current stock-block start index to subset dataframe\n",
    "\n",
    "#     # Iterate over the list with access to the next row\n",
    "#     for i in range(len(rows) - 1):\n",
    "#         current_index, current_row = rows[i]\n",
    "#         ticker = current_row[\"stock\"]\n",
    "\n",
    "#         next_index, next_row = rows[i + 1]\n",
    "\n",
    "#         if next_row[\"stock\"] != ticker:\n",
    "#             print(\"Processing stock: \", ticker, \" | progress: \" , (len(merged_df)/len(headline_data)))\n",
    "#             # create subset, merge, insert in plain\n",
    "#             temp_headline_dataset = headline_data.iloc[start_block_idx:current_index]\n",
    "            \n",
    "#             try:\n",
    "#                 raw_stock_data = pd.read_csv(f'stocks/{ticker}.csv') # read the current stock prices\n",
    "#             except:\n",
    "#                 continue\n",
    "#             raw_stock_data = raw_stock_data.rename(columns={'Date': 'date'})\n",
    "\n",
    "#             # Calculate difference as boolean and numeric\n",
    "#             raw_stock_data[\"diff_num\"] = raw_stock_data[\"Close\"] - raw_stock_data[\"Open\"]\n",
    "#             raw_stock_data[\"diff_bool\"] = raw_stock_data[\"diff_num\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "#             # Make a small DF and join with headline data\n",
    "#             stock_data = raw_stock_data[[\"date\",\"diff_bool\"]]\n",
    "#             temp_merged_df = pd.merge(temp_headline_dataset, stock_data, on='date', how='inner')\n",
    "#             temp_merged_df = temp_merged_df[[\"title\",\"diff_bool\",\"stock\"]]\n",
    "\n",
    "#             merged_df = pd.concat([merged_df, temp_merged_df], axis=0, ignore_index=True) #merging to the overall dataset\n",
    "\n",
    "#             # setting variables for further iteration of next stock-block\n",
    "#             start_block_idx = next_index\n",
    "#             ticker = next_row[\"stock\"]\n",
    "\n",
    "#     #export the csv so that the computation does not always have to be made\n",
    "#     merged_df.to_csv(\"big_merged_dataset.csv\",index=False)\n",
    "\n",
    "# df = merged_df\n",
    "# print(\"Length is: \" , len(df), \" rows\")\n",
    "# print(\"The dataset holds \", round((len(merged_df)/len(headline_data))*100,2) , \"% of the overall rows.\")\n",
    "# df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>diff_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  diff_bool\n",
       "0  is upset that he can't update his Facebook by ...          0\n",
       "1  @Kenichan I dived many times for the ball. Man...          0\n",
       "2    my whole body feels itchy and like its on fire           0\n",
       "3  @nationwideclass no, it's not behaving at all....          0\n",
       "4                      @Kwesidei not the whole crew           0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding='latin-1')\n",
    "df = df.iloc[:, [0, 5]]\n",
    "df.columns.values[0] = \"diff_bool\"\n",
    "df.columns.values[1] = \"title\"\n",
    "df[\"diff_bool\"] = df[\"diff_bool\"].replace(4, 1)\n",
    "df = df.loc[:,['title','diff_bool']]\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  is upset that he can't update his Facebook by ...      0\n",
       "1  @Kenichan I dived many times for the ball. Man...      0\n",
       "2    my whole body feels itchy and like its on fire       0\n",
       "3  @nationwideclass no, it's not behaving at all....      0\n",
       "4                      @Kwesidei not the whole crew       0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df[[\"title\",\"diff_bool\"]]\n",
    "dataset = dataset.rename(columns = {'diff_bool':'label'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120640</th>\n",
       "      <td>i have to write a speech on &amp;quot;speeches&amp;quo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189703</th>\n",
       "      <td>Yeah, this is just great, sick in the middle o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595284</th>\n",
       "      <td>anyway, gotta go.. CSI: NY up next and I have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021096</th>\n",
       "      <td>@skimhannahkeys @AliciaSkimbit i like your app...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98291</th>\n",
       "      <td>@Lolene ummmmm.... U disappeared... So much fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  label\n",
       "120640   i have to write a speech on &quot;speeches&quo...      0\n",
       "189703   Yeah, this is just great, sick in the middle o...      0\n",
       "1595284  anyway, gotta go.. CSI: NY up next and I have ...      1\n",
       "1021096  @skimhannahkeys @AliciaSkimbit i like your app...      1\n",
       "98291    @Lolene ummmmm.... U disappeared... So much fo...      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for weak computation power, smaple n rows\n",
    "dataset = dataset.sample(n=8000, random_state=1)\n",
    "print(len(dataset))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for row in dataset[\"title\"]:\n",
    "    if len(row) > max_len:\n",
    "        max_len = len(row)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     title  label  leng\n",
      "120640   i have to write a speech on &quot;speeches&quo...      0    67\n",
      "189703   Yeah, this is just great, sick in the middle o...      0   135\n",
      "1595284  anyway, gotta go.. CSI: NY up next and I have ...      1    89\n",
      "1021096  @skimhannahkeys @AliciaSkimbit i like your app...      1   110\n",
      "98291    @Lolene ummmmm.... U disappeared... So much fo...      0    58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.061625"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"leng\"] = dataset[\"title\"].apply(lambda x: len(x))\n",
    "print(dataset.head())\n",
    "dataset[\"leng\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8000, 36)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize, Indexing, Padding \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=20000)  # num_words is the maximum number of words to keep\n",
    "\n",
    "titles = dataset[\"title\"].to_numpy()\n",
    "\n",
    "# Fit the tokenizer on the data\n",
    "tokenizer.fit_on_texts(titles)\n",
    "\n",
    "# Tokenize and index the sentences\n",
    "seq = tokenizer.texts_to_sequences(titles)\n",
    "\n",
    "# convert sequences to a padding sequence \n",
    "pad = tf.keras.preprocessing.sequence.pad_sequences(seq, padding='post')\n",
    "\n",
    "# labels\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "print(np.max(pad))\n",
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pad, \n",
    "    labels, \n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.5285 - loss: 1.1495 - val_accuracy: 0.6463 - val_loss: 0.6198\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8106 - loss: 0.4961 - val_accuracy: 0.6825 - val_loss: 0.7276\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8878 - loss: 0.2985 - val_accuracy: 0.6862 - val_loss: 1.3976\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9691 - loss: 0.1242 - val_accuracy: 0.6888 - val_loss: 1.5279\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9843 - loss: 0.1070 - val_accuracy: 0.6850 - val_loss: 1.8777\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0838 - val_accuracy: 0.6888 - val_loss: 2.3570\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9814 - loss: 0.0924 - val_accuracy: 0.6806 - val_loss: 2.1466\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9710 - loss: 0.1592 - val_accuracy: 0.6906 - val_loss: 2.4139\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9883 - loss: 0.0904 - val_accuracy: 0.6794 - val_loss: 2.6334\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9941 - loss: 0.0824 - val_accuracy: 0.6819 - val_loss: 2.8668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27d05469ae0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) \n",
    "d = 64\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size+1, \n",
    "    output_dim=d, mask_zero = True), \n",
    "    tf.keras.layers.LSTM(d),\n",
    "    tf.keras.layers.Dense(d, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64,\n",
    "          validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"big_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    4008\n",
      "1    3992\n",
      "Name: count, dtype: int64\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.94428784, 4.117477, 0.6187894)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[\"label\"].value_counts())\n",
    "pred = model.predict(X_test)\n",
    "np.min(pred), np.max(pred), np.mean(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
