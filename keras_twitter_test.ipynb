{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/gabriel/.local/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: packaging in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (2.32.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: rich in /home/gabriel/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/gabriel/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/gabriel/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gabriel/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/gabriel/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/gabriel/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gabriel/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/gabriel/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/gabriel/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /home/gabriel/.local/lib/python3.10/site-packages (3.3.3)\n",
      "Requirement already satisfied: numpy in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: absl-py in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: rich in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: h5py in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: namex in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/gabriel/.local/lib/python3.10/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/gabriel/.local/lib/python3.10/site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/gabriel/.local/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gabriel/.local/lib/python3.10/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/gabriel/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "# %pip install tensorflow-rocm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ----------------\n",
      "absl-py                      2.1.0\n",
      "amdsmi                       24.4.1+afcd367\n",
      "annotated-types              0.7.0\n",
      "anyio                        4.3.0\n",
      "appdirs                      1.4.4\n",
      "apturl                       0.5.2\n",
      "argcomplete                  1.8.1\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        23.2.0\n",
      "Babel                        2.15.0\n",
      "backcall                     0.2.0\n",
      "bcrypt                       3.2.0\n",
      "beautifulsoup4               4.10.0\n",
      "beniget                      0.4.1\n",
      "bleach                       6.1.0\n",
      "blinker                      1.4\n",
      "blis                         0.7.11\n",
      "Brlapi                       0.8.3\n",
      "Brotli                       1.0.9\n",
      "cachetools                   5.3.3\n",
      "catalogue                    2.0.10\n",
      "certifi                      2020.6.20\n",
      "cffi                         1.16.0\n",
      "chardet                      4.0.0\n",
      "charset-normalizer           3.3.2\n",
      "clang                        17.0.6\n",
      "click                        8.0.3\n",
      "cloudpathlib                 0.16.0\n",
      "colorama                     0.4.4\n",
      "comm                         0.2.2\n",
      "command-not-found            0.3\n",
      "confection                   0.1.4\n",
      "cryptography                 3.4.8\n",
      "cupshelpers                  1.0\n",
      "cycler                       0.11.0\n",
      "cymem                        2.0.8\n",
      "dbus-python                  1.2.18\n",
      "debugpy                      1.8.1\n",
      "decorator                    5.1.1\n",
      "defer                        1.0.6\n",
      "defusedxml                   0.7.1\n",
      "distro                       1.7.0\n",
      "distro-info                  1.1+ubuntu0.2\n",
      "dm-tree                      0.1.8\n",
      "docker                       5.0.3\n",
      "docker-compose               1.29.2\n",
      "dockerpty                    0.4.1\n",
      "docopt                       0.6.2\n",
      "duplicity                    0.8.21\n",
      "en-core-web-sm               3.7.1\n",
      "entrypoints                  0.4\n",
      "exceptiongroup               1.2.1\n",
      "executing                    2.0.1\n",
      "fasteners                    0.14.1\n",
      "fastjsonschema               2.19.1\n",
      "filelock                     3.13.1\n",
      "flatbuffers                  24.3.25\n",
      "fonttools                    4.29.1\n",
      "fqdn                         1.5.1\n",
      "fs                           2.4.12\n",
      "fsspec                       2024.2.0\n",
      "future                       0.18.2\n",
      "gast                         0.5.4\n",
      "google-auth                  2.29.0\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.63.0\n",
      "h11                          0.14.0\n",
      "h5py                         3.11.0\n",
      "html5lib                     1.1\n",
      "httpcore                     1.0.5\n",
      "httplib2                     0.20.2\n",
      "httpx                        0.27.0\n",
      "idna                         3.3\n",
      "importlib-metadata           4.6.4\n",
      "ipykernel                    6.29.4\n",
      "ipython                      8.24.0\n",
      "ipython_genutils             0.2.0\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "jeepney                      0.7.1\n",
      "Jinja2                       3.1.3\n",
      "joblib                       1.4.2\n",
      "json5                        0.9.25\n",
      "jsonpointer                  2.4\n",
      "jsonschema                   4.22.0\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter_client               7.4.9\n",
      "jupyter_core                 5.7.2\n",
      "jupyter-events               0.10.0\n",
      "jupyter-lsp                  2.2.5\n",
      "jupyter_server               2.14.0\n",
      "jupyter_server_terminals     0.5.3\n",
      "jupyterlab                   4.2.0\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.27.1\n",
      "keras                        3.3.3\n",
      "keyring                      23.5.0\n",
      "kiwisolver                   1.3.2\n",
      "langcodes                    3.4.0\n",
      "language_data                1.2.0\n",
      "language-selector            0.1\n",
      "launchpadlib                 1.10.16\n",
      "lazr.restfulclient           0.14.4\n",
      "lazr.uri                     1.0.6\n",
      "libclang                     18.1.1\n",
      "lockfile                     0.12.2\n",
      "louis                        3.20.0\n",
      "lxml                         4.8.0\n",
      "lz4                          3.1.3+dfsg\n",
      "macaroonbakery               1.3.1\n",
      "Mako                         1.1.3\n",
      "marisa-trie                  1.1.1\n",
      "Markdown                     3.6\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib                   3.5.1\n",
      "matplotlib-inline            0.1.7\n",
      "mdurl                        0.1.2\n",
      "mistune                      3.0.2\n",
      "ml-dtypes                    0.3.2\n",
      "monotonic                    1.6\n",
      "more-itertools               8.10.0\n",
      "mpmath                       0.0.0\n",
      "murmurhash                   1.0.10\n",
      "namex                        0.0.8\n",
      "nbclient                     0.10.0\n",
      "nbconvert                    7.16.4\n",
      "nbformat                     5.10.4\n",
      "nest-asyncio                 1.6.0\n",
      "netifaces                    0.11.0\n",
      "networkx                     3.2.1\n",
      "nltk                         3.8.1\n",
      "notebook                     7.2.0\n",
      "notebook_shim                0.2.4\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.0\n",
      "olefile                      0.46\n",
      "opt-einsum                   3.3.0\n",
      "optree                       0.11.0\n",
      "overrides                    7.7.0\n",
      "packaging                    24.0\n",
      "pandas                       2.2.2\n",
      "pandocfilters                1.5.1\n",
      "paramiko                     2.9.3\n",
      "parso                        0.8.4\n",
      "pexpect                      4.8.0\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.0.1\n",
      "pip                          22.0.2\n",
      "platformdirs                 4.2.1\n",
      "ply                          3.11\n",
      "preshed                      3.0.9\n",
      "prometheus_client            0.20.0\n",
      "prompt-toolkit               3.0.43\n",
      "protobuf                     4.25.3\n",
      "psutil                       5.9.8\n",
      "ptyprocess                   0.7.0\n",
      "pure-eval                    0.2.2\n",
      "py                           1.10.0\n",
      "pyasn1                       0.6.0\n",
      "pyasn1_modules               0.4.0\n",
      "pycairo                      1.20.1\n",
      "pycparser                    2.22\n",
      "pycups                       2.0.1\n",
      "pydantic                     2.7.1\n",
      "pydantic_core                2.18.2\n",
      "Pygments                     2.18.0\n",
      "PyGObject                    3.42.1\n",
      "PyJWT                        2.3.0\n",
      "pymacaroons                  0.13.0\n",
      "PyNaCl                       1.5.0\n",
      "pyparsing                    2.4.7\n",
      "pyRFC3339                    1.1\n",
      "pyrsistent                   0.18.1\n",
      "python-apt                   2.4.0+ubuntu3\n",
      "python-dateutil              2.9.0.post0\n",
      "python-debian                0.1.43+ubuntu1.1\n",
      "python-dotenv                0.19.2\n",
      "python-json-logger           2.0.7\n",
      "python-version               0.0.2\n",
      "pythran                      0.10.0\n",
      "pytorch-triton-rocm          2.3.0\n",
      "pytz                         2022.1\n",
      "pyxdg                        0.27\n",
      "PyYAML                       5.4.1\n",
      "pyzmq                        24.0.1\n",
      "referencing                  0.35.1\n",
      "regex                        2024.4.28\n",
      "reportlab                    3.6.8\n",
      "requests                     2.32.1\n",
      "requests-oauthlib            2.0.0\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rich                         13.7.1\n",
      "rpds-py                      0.18.1\n",
      "rsa                          4.9\n",
      "scikit-learn                 1.4.2\n",
      "scipy                        1.8.0\n",
      "seaborn                      0.13.2\n",
      "SecretStorage                3.3.1\n",
      "Send2Trash                   1.8.3\n",
      "sentencepiece                0.2.0\n",
      "setuptools                   59.6.0\n",
      "six                          1.16.0\n",
      "smart-open                   6.4.0\n",
      "sniffio                      1.3.1\n",
      "soupsieve                    2.3.1\n",
      "spacy                        3.7.4\n",
      "spacy-legacy                 3.0.12\n",
      "spacy-loggers                1.0.5\n",
      "srsly                        2.4.8\n",
      "stack-data                   0.6.3\n",
      "sympy                        1.9\n",
      "systemd-python               234\n",
      "tensorboard                  2.16.2\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.16.1\n",
      "tensorflow-estimator         2.14.0\n",
      "tensorflow-io-gcs-filesystem 0.37.0\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.1\n",
      "texttable                    1.6.4\n",
      "thinc                        8.2.3\n",
      "threadpoolctl                3.5.0\n",
      "tinycss2                     1.3.0\n",
      "tomli                        2.0.1\n",
      "torch                        2.3.0+rocm6.0\n",
      "torchaudio                   2.3.0+rocm6.0\n",
      "torchtext                    0.6.0\n",
      "torchvision                  0.18.0+rocm6.0\n",
      "tornado                      6.4\n",
      "tqdm                         4.66.4\n",
      "traitlets                    5.14.3\n",
      "typer                        0.9.4\n",
      "types-python-dateutil        2.9.0.20240316\n",
      "typing_extensions            4.11.0\n",
      "tzdata                       2024.1\n",
      "ubuntu-drivers-common        0.0.0\n",
      "ubuntu-pro-client            8001\n",
      "ufoLib2                      0.13.1\n",
      "ufw                          0.36.1\n",
      "unattended-upgrades          0.1\n",
      "unicodedata2                 14.0.0\n",
      "uri-template                 1.3.0\n",
      "urllib3                      1.26.5\n",
      "usb-creator                  0.3.7\n",
      "wadllib                      1.3.6\n",
      "wasabi                       1.1.2\n",
      "wcwidth                      0.2.13\n",
      "weasel                       0.3.4\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.8.0\n",
      "Werkzeug                     3.0.3\n",
      "wheel                        0.37.1\n",
      "wrapt                        1.14.1\n",
      "xdg                          5\n",
      "xkit                         0.0.0\n",
      "zipp                         1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read headline_data\n",
    "# headline_data = pd.read_csv('analyst_ratings_processed.csv' , quotechar='\"', quoting=2, delimiter=\",\")\n",
    "\n",
    "# # subset A stock for development-stage\n",
    "# headline_data = headline_data[headline_data[\"stock\"]==\"A\"]\n",
    "\n",
    "# # Cut only date from datetime value\n",
    "# headline_data[\"date\"] = headline_data[\"date\"].apply(lambda x: x.split(\" \")[0])\n",
    "\n",
    "# # Read Stock Data (only A for development-stage)\n",
    "# raw_stock_data = pd.read_csv('A.csv')\n",
    "\n",
    "# # Preprocessing\n",
    "# raw_stock_data = raw_stock_data.rename(columns={'Date': 'date'})\n",
    "\n",
    "# # Calculate difference as boolean and numeric\n",
    "# raw_stock_data[\"diff_num\"] = raw_stock_data[\"Open\"] - raw_stock_data[\"Close\"]\n",
    "# raw_stock_data[\"diff_bool\"] = raw_stock_data[\"diff_num\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# # Add label A for joining\n",
    "# raw_stock_data[\"label\"] = \"A\"\n",
    "\n",
    "# # Make a small DF and join with headline data\n",
    "# stock_data = raw_stock_data[[\"date\",\"label\", \"diff_num\",\"diff_bool\"]]\n",
    "# #print(stock_data[stock_data[\"diff_bool\"]==1])\n",
    "# merged_df = pd.merge(headline_data, stock_data, on='date', how='inner')\n",
    "\n",
    "# # Drop unneccesary columns\n",
    "# #merged_df = merged_df.drop(merged_df.columns[0], axis=1)\n",
    "# # merged_df = merged_df.drop(columns=[\"label_x\",\"label_y\"])\n",
    "# merged_df.head()\n",
    "\n",
    "# #merged_df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df[(merged_df[\"diff_num\"]<0.01) & (merged_df[\"diff_num\"]>-0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "\n",
    "# if os.path.exists(\"big_merged_dataset.csv\"):\n",
    "#     # Read the CSV file\n",
    "#     merged_df = pd.read_csv(\"big_merged_dataset.csv\")\n",
    "#     headline_data = pd.read_csv('analyst_ratings_processed.csv' , quotechar='\"', quoting=2, delimiter=\",\")\n",
    "#     print(\"CSV file exists. DataFrame loaded successfully.\")\n",
    "# else:\n",
    "#     print(\"CSV file does not exist. Processing starts, this takes approximately 3 minutes\")\n",
    "\n",
    "#     headline_data = pd.read_csv('analyst_ratings_processed.csv' , quotechar='\"', quoting=2, delimiter=\",\")\n",
    "\n",
    "\n",
    "\n",
    "#     # Function to check if the value is a string\n",
    "#     def is_string(value):\n",
    "#         return isinstance(value, str)\n",
    "\n",
    "#     # Filter the DataFrame to keep only rows where the 'date' column is a string\n",
    "#     headline_data = headline_data[headline_data['date'].apply(is_string)]\n",
    "#     print(len(headline_data))\n",
    "\n",
    "\n",
    "\n",
    "#     headline_data[\"date\"] = headline_data[\"date\"].apply(lambda x: x.split(\" \")[0])\n",
    "#     print(\"Date processing done.\")\n",
    "\n",
    "\n",
    "\n",
    "#     # iterable list\n",
    "#     rows = list(headline_data.iterrows())\n",
    "#     print(\"Iterable list transformation done.\")\n",
    "\n",
    "#     merged_df = pd.DataFrame(columns=[\"title\",\"diff_bool\",\"stock\"])\n",
    "#     ticker = \"\"  # save the current stock ticker\n",
    "#     start_block_idx = 0     # save the current stock-block start index to subset dataframe\n",
    "\n",
    "#     # Iterate over the list with access to the next row\n",
    "#     for i in range(len(rows) - 1):\n",
    "#         current_index, current_row = rows[i]\n",
    "#         ticker = current_row[\"stock\"]\n",
    "\n",
    "#         next_index, next_row = rows[i + 1]\n",
    "\n",
    "#         if next_row[\"stock\"] != ticker:\n",
    "#             print(\"Processing stock: \", ticker, \" | progress: \" , (len(merged_df)/len(headline_data)))\n",
    "#             # create subset, merge, insert in plain\n",
    "#             temp_headline_dataset = headline_data.iloc[start_block_idx:current_index]\n",
    "            \n",
    "#             try:\n",
    "#                 raw_stock_data = pd.read_csv(f'stocks/{ticker}.csv') # read the current stock prices\n",
    "#             except:\n",
    "#                 continue\n",
    "#             raw_stock_data = raw_stock_data.rename(columns={'Date': 'date'})\n",
    "\n",
    "#             # Calculate difference as boolean and numeric\n",
    "#             raw_stock_data[\"diff_num\"] = raw_stock_data[\"Close\"] - raw_stock_data[\"Open\"]\n",
    "#             raw_stock_data[\"diff_bool\"] = raw_stock_data[\"diff_num\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "#             # Make a small DF and join with headline data\n",
    "#             stock_data = raw_stock_data[[\"date\",\"diff_bool\"]]\n",
    "#             temp_merged_df = pd.merge(temp_headline_dataset, stock_data, on='date', how='inner')\n",
    "#             temp_merged_df = temp_merged_df[[\"title\",\"diff_bool\",\"stock\"]]\n",
    "\n",
    "#             merged_df = pd.concat([merged_df, temp_merged_df], axis=0, ignore_index=True) #merging to the overall dataset\n",
    "\n",
    "#             # setting variables for further iteration of next stock-block\n",
    "#             start_block_idx = next_index\n",
    "#             ticker = next_row[\"stock\"]\n",
    "\n",
    "#     #export the csv so that the computation does not always have to be made\n",
    "#     merged_df.to_csv(\"big_merged_dataset.csv\",index=False)\n",
    "\n",
    "# df = merged_df\n",
    "# print(\"Length is: \" , len(df), \" rows\")\n",
    "# print(\"The dataset holds \", round((len(merged_df)/len(headline_data))*100,2) , \"% of the overall rows.\")\n",
    "# df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>diff_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  diff_bool\n",
       "0  is upset that he can't update his Facebook by ...          0\n",
       "1  @Kenichan I dived many times for the ball. Man...          0\n",
       "2    my whole body feels itchy and like its on fire           0\n",
       "3  @nationwideclass no, it's not behaving at all....          0\n",
       "4                      @Kwesidei not the whole crew           0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding='latin-1')\n",
    "df = df.iloc[:, [0, 5]]\n",
    "df.columns.values[0] = \"diff_bool\"\n",
    "df.columns.values[1] = \"title\"\n",
    "df[\"diff_bool\"] = df[\"diff_bool\"].replace(4, 1)\n",
    "df = df.loc[:,['title','diff_bool']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  is upset that he can't update his Facebook by ...      0\n",
       "1  @Kenichan I dived many times for the ball. Man...      0\n",
       "2    my whole body feels itchy and like its on fire       0\n",
       "3  @nationwideclass no, it's not behaving at all....      0\n",
       "4                      @Kwesidei not the whole crew       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df[[\"title\",\"diff_bool\"]]\n",
    "dataset = dataset.rename(columns = {'diff_bool':'label'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120640</th>\n",
       "      <td>i have to write a speech on &amp;quot;speeches&amp;quo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189703</th>\n",
       "      <td>Yeah, this is just great, sick in the middle o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595284</th>\n",
       "      <td>anyway, gotta go.. CSI: NY up next and I have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021096</th>\n",
       "      <td>@skimhannahkeys @AliciaSkimbit i like your app...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98291</th>\n",
       "      <td>@Lolene ummmmm.... U disappeared... So much fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  label\n",
       "120640   i have to write a speech on &quot;speeches&quo...      0\n",
       "189703   Yeah, this is just great, sick in the middle o...      0\n",
       "1595284  anyway, gotta go.. CSI: NY up next and I have ...      1\n",
       "1021096  @skimhannahkeys @AliciaSkimbit i like your app...      1\n",
       "98291    @Lolene ummmmm.... U disappeared... So much fo...      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for weak computation power, smaple n rows\n",
    "dataset = dataset.sample(n=15000, random_state=1)\n",
    "print(len(dataset))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for row in dataset[\"title\"]:\n",
    "    if len(row) > max_len:\n",
    "        max_len = len(row)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     title  label  leng\n",
      "120640   i have to write a speech on &quot;speeches&quo...      0    67\n",
      "189703   Yeah, this is just great, sick in the middle o...      0   135\n",
      "1595284  anyway, gotta go.. CSI: NY up next and I have ...      1    89\n",
      "1021096  @skimhannahkeys @AliciaSkimbit i like your app...      1   110\n",
      "98291    @Lolene ummmmm.... U disappeared... So much fo...      0    58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.24406666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"leng\"] = dataset[\"title\"].apply(lambda x: len(x))\n",
    "print(dataset.head())\n",
    "dataset[\"leng\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15000, 36)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize, Indexing, Padding \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=20000)  # num_words is the maximum number of words to keep\n",
    "\n",
    "titles = dataset[\"title\"].to_numpy()\n",
    "\n",
    "# Fit the tokenizer on the data\n",
    "tokenizer.fit_on_texts(titles)\n",
    "\n",
    "# Tokenize and index the sentences\n",
    "seq = tokenizer.texts_to_sequences(titles)\n",
    "\n",
    "# convert sequences to a padding sequence \n",
    "pad = tf.keras.preprocessing.sequence.pad_sequences(seq, padding='post')\n",
    "\n",
    "# labels\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "print(np.max(pad))\n",
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pad, \n",
    "    labels, \n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.5123 - loss: 1.3936 - val_accuracy: 0.6660 - val_loss: 0.6437\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7689 - loss: 0.5163 - val_accuracy: 0.7113 - val_loss: 0.7147\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8765 - loss: 0.3621 - val_accuracy: 0.6730 - val_loss: 0.7842\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9147 - loss: 0.2740 - val_accuracy: 0.7053 - val_loss: 1.6503\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9608 - loss: 0.1688 - val_accuracy: 0.6943 - val_loss: 1.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70059f708c40>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) \n",
    "d = 64\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size+1, \n",
    "    output_dim=d, mask_zero = True), \n",
    "    tf.keras.layers.LSTM(d),\n",
    "    tf.keras.layers.Dense(d, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64,\n",
    "          validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"big_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    7563\n",
      "0    7437\n",
      "Name: count, dtype: int64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.2743802, 5.1354914, 0.575027)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[\"label\"].value_counts())\n",
    "pred = model.predict(X_test)\n",
    "np.min(pred), np.max(pred), np.mean(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4985 - loss: 1.3881 - val_accuracy: 0.5137 - val_loss: 0.7690\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5453 - loss: 0.7320 - val_accuracy: 0.5867 - val_loss: 0.6785\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6705 - loss: 0.5998 - val_accuracy: 0.6677 - val_loss: 0.6415\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7957 - loss: 0.4392 - val_accuracy: 0.6900 - val_loss: 0.6354\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8307 - loss: 0.3844 - val_accuracy: 0.7033 - val_loss: 0.7261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x700535cac7f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) \n",
    "d = 2\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size+1, \n",
    "    output_dim=d, mask_zero = True), \n",
    "    tf.keras.layers.LSTM(d),\n",
    "    tf.keras.layers.Dense(d, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64,\n",
    "          validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.028934479, 1.5413748, 0.46873787)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "np.min(pred), np.max(pred), np.mean(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
